{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "258561e8-2ee1-43d5-8226-c47b6bab34c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this if you are unable to download the dataset_url\n",
    "#!pip install opendatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cabee4ce-f88e-47d4-9de0-064809c69553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \"./chest-xray-covid19-pneumonia\" (use force=True to force download)\n"
     ]
    }
   ],
   "source": [
    "# /*To download data set*/\n",
    "\n",
    "import opendatasets as od\n",
    "dataset_url = 'https://www.kaggle.com/datasets/prashant268/chest-xray-covid19-pneumonia'\n",
    "od.download(dataset_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f258dfce-dd0a-4cfd-b3cb-45c40108606f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['COVID19', 'PNEUMONIA', 'NORMAL']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataroot = 'chest-xray-covid19-pneumonia/Data/train/'\n",
    "#  NORMAL , PNEUMONIA\n",
    "import os\n",
    "#Copy the directory name for training\n",
    "os.listdir(dataroot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99ffe8b3-23c5-42da-8752-344fdcc9eb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ee0828f-4883-4f9b-9fc5-ff019c256e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channels_img, features_d):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                channels_img, features_d, kernel_size=4, stride=2, padding=1\n",
    "            ),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            self._block(features_d, features_d * 2, 4, 2, 1),\n",
    "            self._block(features_d * 2, features_d * 4, 4, 2, 1),\n",
    "            self._block(features_d * 4, features_d * 8, 4, 2, 1),\n",
    "            nn.Conv2d(features_d * 8, 1, kernel_size=4, stride=2, padding=0),\n",
    "        )\n",
    "\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size,\n",
    "                stride,\n",
    "                padding,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.InstanceNorm2d(out_channels, affine=True),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.disc(x)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, channels_noise, channels_img, features_g):\n",
    "        super(Generator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            self._block(channels_noise, features_g * 32, 4, 1, 0),\n",
    "            self._block(features_g * 32, features_g * 16, 4, 1, 0),\n",
    "            self._block(features_g * 16, features_g * 8, 4, 2, 1),\n",
    "            self._block(features_g * 8, features_g * 4, 4, 2, 1),\n",
    "            self._block(features_g * 4, features_g * 2, 4, 2, 1),\n",
    "            nn.ConvTranspose2d(\n",
    "                features_g * 2, channels_img, kernel_size=4, stride=2, padding=1\n",
    "            ),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size,\n",
    "                stride,\n",
    "                padding,\n",
    "                bias=False,\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "def initialize_weights(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
    "            nn.init.normal_(m.weight.data, 0.0, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adc0092b-c625-4792-81b6-536163bec90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1ed5799-1ba0-4488-8731-a9ce834f56ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "LEARNING_RATE = 5e-5\n",
    "BATCH_SIZE = 64\n",
    "IMAGE_SIZE = 64\n",
    "CHANNELS_IMG = 3\n",
    "Z_DIM = 128\n",
    "NUM_EPOCHS = 10\n",
    "FEATURES_CRITIC = 64\n",
    "FEATURES_GEN = 64\n",
    "CRITIC_ITERATIONS = 5\n",
    "WEIGHT_CLIP = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2866d179-2a46-4440-8db0-e81475e20e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMAGE_SIZE,IMAGE_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            [0.5 for _ in range(CHANNELS_IMG)], [0.5 for _ in range(CHANNELS_IMG)]\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# # Define the transformations you want to apply to the images\n",
    "#  transform = transforms.Compose([\n",
    "#    transforms.Resize((64, 64)),  # Resize images to a consistent size (for example 64x64)\n",
    "#    transforms.ToTensor(),       # Convert images to tensors\n",
    " #   transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize to [-1, 1]\n",
    "#])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a01fe94c-970b-4b25-9d3f-1f9d3d6d77b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = datasets.ImageFolder(root=dataroot, transform=transforms)\n",
    "#loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bce273bb-24d6-457d-987e-79704bd8ba5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the entire dataset\n",
    "full_dataset = datasets.ImageFolder(root=dataroot, transform=transform)\n",
    "\n",
    "# Filter the dataset to include only images from the \"COVID19\" class folder\n",
    "class_folder = 'COVID19'\n",
    "class_index = full_dataset.class_to_idx[class_folder]\n",
    "filtered_indices = [i for i in range(len(full_dataset)) if full_dataset[i][1] == class_index]\n",
    "\n",
    "# Create a Subset dataset containing only the filtered images\n",
    "from torch.utils.data import Subset\n",
    "subset_dataset = Subset(full_dataset, filtered_indices)\n",
    "\n",
    "# Create a DataLoader to iterate over the subset dataset in batches during training\n",
    "BATCH_SIZE = 64\n",
    "loader = DataLoader(subset_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a9a3a10-ca67-4ba1-a547-d7ff6ad61351",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = Generator(Z_DIM, CHANNELS_IMG, FEATURES_GEN).to(device)\n",
    "critic = Discriminator(CHANNELS_IMG, FEATURES_CRITIC).to(device)\n",
    "initialize_weights(gen)\n",
    "initialize_weights(critic)\n",
    "# ============================above this part not req in case training  loaded model ================\n",
    "\n",
    "opt_gen = optim.RMSprop(gen.parameters(), lr=LEARNING_RATE)\n",
    "opt_critic = optim.RMSprop(critic.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "fixed_noise = torch.randn(32, Z_DIM, 1, 1).to(device)\n",
    "writer_real = SummaryWriter(f\"logs2/real\")\n",
    "writer_fake = SummaryWriter(f\"logs2/fake\")\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8dd302e9-1e43-4a69-9f18-b61b1c3df801",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1610/3678043425.py:50: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  wgan_model = KerasRegressor(build_fn=build_wgan_model, epochs=10, batch_size=32, verbose=0)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "array() missing required argument 'object' (pos 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 60\u001b[0m\n\u001b[1;32m     53\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleaky_relu_alpha\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m0.3\u001b[39m, \u001b[38;5;241m0.4\u001b[39m],\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiscriminator_optimizer\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmsprop\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerator_optimizer\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmsprop\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     57\u001b[0m }\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Data Tracing\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m image_data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(class_index)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Split the data into training, validation and testing sets\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: array() missing required argument 'object' (pos 0)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "\n",
    "# Define the WGAN model function\n",
    "def build_wgan_model(discriminator_optimizer='adam', generator_optimizer='adam', leaky_relu_alpha=0.2):\n",
    "    # Generator\n",
    "    Generator = keras.Sequential([\n",
    "        keras.layers.Dense(256, input_dim=100),\n",
    "        keras.layers.LeakyReLU(alpha=leaky_relu_alpha),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(512),\n",
    "        keras.layers.LeakyReLU(alpha=leaky_relu_alpha),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(1024),\n",
    "        keras.layers.LeakyReLU(alpha=leaky_relu_alpha),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Dense(784, activation='tanh')\n",
    "    ])\n",
    "\n",
    "    # Discriminator\n",
    "    Discriminator = keras.Sequential([\n",
    "        keras.layers.Dense(1024, input_dim=784),\n",
    "        keras.layers.LeakyReLU(alpha=leaky_relu_alpha),\n",
    "        keras.layers.Dense(512),\n",
    "        keras.layers.LeakyReLU(alpha=leaky_relu_alpha),\n",
    "        keras.layers.Dense(256),\n",
    "        keras.layers.LeakyReLU(alpha=leaky_relu_alpha),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    # Compile discriminator\n",
    "    Discriminator.compile(loss='binary_crossentropy', optimizer=discriminator_optimizer)\n",
    "\n",
    "    # The WGAN model\n",
    "    z = keras.layers.Input(shape=(100,))\n",
    "    img = Generator(z)\n",
    "    Discriminator.trainable = False\n",
    "    valid = Discriminator(img)\n",
    "    wgan = keras.Model(z, valid)\n",
    "    wgan.compile(loss='binary_crossentropy', optimizer=generator_optimizer)\n",
    "\n",
    "    return wgan\n",
    "\n",
    "# Create the KerasRegressor for Grid Search\n",
    "wgan_model = KerasRegressor(build_fn=build_wgan_model, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "# Define the hyperparameters to search through\n",
    "param_grid = {\n",
    "    'leaky_relu_alpha': [0.2, 0.3, 0.4],\n",
    "    'discriminator_optimizer': ['adam', 'rmsprop'],\n",
    "    'generator_optimizer': ['adam', 'rmsprop']\n",
    "}\n",
    "\n",
    "# Data Tracing\n",
    "# image_data = np.array()\n",
    "# labels = np.array(class_index)\n",
    "\n",
    "# Split the data into training, validation and testing sets\n",
    "# X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Perform Grid Search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=wgan_model, param_grid=param_grid, n_jobs=-1)\n",
    "grid_result = grid_search.fit(X_train, y_train)  # X_train and y_train are your data and labels\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff38fb85-716e-4a38-b5e8-622b8f0c00b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (disc): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "    (2): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "    (5): Conv2d(512, 1, kernel_size=(4, 4), stride=(2, 2))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.train()\n",
    "critic.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ce53ab6-0e9f-4588-b304-a660e2937e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ccb9165-b7d5-4a13-801a-eea98a59bd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you again load the trained model to retrain it \n",
    "\n",
    "#gen = Generator(Z_DIM, CHANNELS_IMG, FEATURES_GEN).to(device)\n",
    "#gen.load_state_dict(torch.load('/content/drive/MyDrive/GAN128.pth', map_location='cpu'))\n",
    "\n",
    "# critic = Discriminator(CHANNELS_IMG, FEATURES_CRITIC).to(device)\n",
    "# critic.load_state_dict(torch.load('/content/drive/MyDrive/Diff-x1r.pth', map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff9d0219-c0c5-4747-8b46-30bb221b9393",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.utils as vutils\n",
    "j = int(32)\n",
    "img_list = []\n",
    "for epoch in range(500):\n",
    "    for batch_idx, (data, _) in enumerate(loader):\n",
    "        data = data.to(device)\n",
    "        cur_batch_size = data.shape[0]\n",
    "        for _ in range(CRITIC_ITERATIONS):\n",
    "            noise = torch.randn(cur_batch_size, Z_DIM, 1, 1).to(device)\n",
    "            fake = gen(noise)\n",
    "            critic_real = critic(data).reshape(-1)\n",
    "            critic_fake = critic(fake).reshape(-1)\n",
    "            loss_critic = -(torch.mean(critic_real) - torch.mean(critic_fake))\n",
    "            critic.zero_grad()\n",
    "            loss_critic.backward(retain_graph=True)\n",
    "            opt_critic.step()\n",
    "            for p in critic.parameters():\n",
    "                p.data.clamp_(-WEIGHT_CLIP, WEIGHT_CLIP)\n",
    "        gen_fake = critic(fake).reshape(-1)\n",
    "        loss_gen = -torch.mean(gen_fake)\n",
    "        gen.zero_grad()\n",
    "        loss_gen.backward()\n",
    "        opt_gen.step()\n",
    "        if batch_idx % 20 == 0 and batch_idx > 0:\n",
    "            gen.eval()\n",
    "            critic.eval()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                fake = gen(noise)\n",
    "                img_grid_real = torchvision.utils.make_grid(\n",
    "                    data[:32], normalize=True\n",
    "                )\n",
    "                img_grid_fake = torchvision.utils.make_grid(\n",
    "                    fake[:32], normalize=True\n",
    "                )\n",
    "                i = int(0)\n",
    "                torchvision.utils.save_image(img_grid_fake, \"generated_image/%04s.jpg\" %step)\n",
    "\n",
    "            step += 1\n",
    "            gen.train()\n",
    "            critic.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c08bae1f-dc4c-4ce2-a541-b322e08effd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gen.state_dict(), 'ank_covid_gan_128.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3577d924-95d5-461c-a6b9-b91ecccf0689",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#from sklearn.datasets import load_iris\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.svm import SVC\n",
    "#from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "#from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10a5258b-aab2-4f87-8b46-1c8f99891bac",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Load the iris dataset\n",
    "#data = load_iris()\n",
    "#X = dataroot.data\n",
    "#y = dataroot.target\n",
    "# Split the data into training, validation, and test sets\n",
    "#X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "#X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe615d53-d85d-4ef7-91c3-72663220c153",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  param_grid = {\n",
    "    'C': [0.1, 1, 10],        # Regularization parameter\n",
    "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "    'gamma': [0.1, 1, 'scale', 'auto']\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08875f6f-6004-4564-afbc-e86cc330cbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" # Initialize the SVM classifier\n",
    "svm = SVC()\n",
    "grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params_grid = grid_search.best_params_\n",
    "\n",
    "# Train the model with the best hyperparameters on the combined training and validation sets\n",
    "best_svm_grid = SVC(**best_params_grid)\n",
    "best_svm_grid.fit(np.vstack((X_train, X_val)), np.hstack((y_train, y_val)))\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred_grid = best_svm_grid.predict(X_test)\n",
    "accuracy_grid = accuracy_score(y_test, y_pred_grid)\n",
    "print(\"Accuracy (Grid Search):\", accuracy_grid)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90dca75-9811-4279-8239-39910e809701",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
